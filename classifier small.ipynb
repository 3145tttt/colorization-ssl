{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea48fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Food101\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from FoodData import FoodDataset, FoodColorizationDataset\n",
    "from utils import collect_train_val, get_classes_map, split_in_out_domain, split_train\n",
    "from Autoencoder import Autoencoder\n",
    "\n",
    "ROOT_DIR = '../'\n",
    "CHECKPOINT_DIR = './checkpoint_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa45879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Food101(ROOT_DIR, split='train', transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = Food101(ROOT_DIR, split='test', transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895bd6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['guacamole', 'spring_rolls', 'carrot_cake', 'paella',\n",
       "       'lobster_bisque', 'chicken_wings', 'ravioli', 'sashimi',\n",
       "       'peking_duck', 'peking_duck', 'scallops', 'tuna_tartare',\n",
       "       'churros', 'baklava', 'chocolate_cake', 'gyoza', 'baby_back_ribs',\n",
       "       'scallops', 'cup_cakes', 'filet_mignon'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "class_to_id, id_to_class = get_classes_map(ROOT_DIR)\n",
    "classes = np.array(list(class_to_id.keys()))\n",
    "out_id = np.random.choice(len(classes), 20)\n",
    "out_classes = classes[out_id]\n",
    "out_classes_id = list([class_to_id[x] for x in out_classes])\n",
    "out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeaf1f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files, train_target, val_target =\\\n",
    "    collect_train_val(ROOT_DIR)\n",
    "\n",
    "train_in_files, train_in_target, train_out_files, train_out_target =\\\n",
    "    split_in_out_domain(train_files, train_target, out_classes_id)\n",
    "\n",
    "_, train_class_files, _, train_class_target =\\\n",
    "    split_train(train_in_files, train_in_target)\n",
    "\n",
    "_, train_class_files_out, _, train_class_target_out =\\\n",
    "    split_train(train_out_files, train_out_target)\n",
    "\n",
    "val_in_files, val_in_target, val_out_files, val_out_target =\\\n",
    "    split_in_out_domain(val_files, val_target, out_classes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3238b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_colorization_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Grayscale()\n",
    "        ])\n",
    "transform_colorization_valid = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True),\n",
    "            transforms.Grayscale()\n",
    "        ])\n",
    "\n",
    "transform_classic_train = transforms.Compose([\n",
    "            transforms.TrivialAugmentWide(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True),\n",
    "            transforms.RandomHorizontalFlip()\n",
    "        ])\n",
    "transform_classic_valid = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((128, 128), antialias=True),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35d779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden, out_channels):\n",
    "        super().__init__()\n",
    "        self.basic_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.basic_block(x)\n",
    "\n",
    "class ResNetFoodClassifierSmall(nn.Module):\n",
    "    def __init__(self, prefix, in_channels, classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.back_bone_prefix = prefix\n",
    "        \n",
    "        for parametr in self.back_bone_prefix.parameters():\n",
    "            parametr.requires_grad = False\n",
    "            \n",
    "        \n",
    "        self.basic_block = BasicBlock(in_channels, 128, 256)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.out = nn.Linear(256, classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.back_bone_prefix(x)\n",
    "        x = self.basic_block(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c6296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(logits, target):\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    return torch.sum(pred == target).item() / pred.size(0)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, valid_loader, loss_fn, metric_fn, step):\n",
    "    model.eval()\n",
    "    \n",
    "    loss, metric = 0, 0\n",
    "    count = 0\n",
    "    for X_batch, target in valid_loader:\n",
    "        X_batch, target = X_batch.cuda(), target.cuda()\n",
    "\n",
    "        out = model(X_batch)\n",
    "        loss += loss_fn(out, target).item() * out.size(0)\n",
    "        metric += metric_fn(out, target) * out.size(0)\n",
    "        count += out.size(0)\n",
    "        \n",
    "    loss /= count\n",
    "    metric /= count\n",
    "    wandb.log({\"eval/loss\": loss, \"eval/metric\": metric}, step=step)\n",
    "    \n",
    "    return loss, metric\n",
    "    \n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, loss_fn, metric_fn, step):\n",
    "    model.train()\n",
    "    for X_batch, target in train_loader:\n",
    "        X_batch, target = X_batch.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_batch)\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metric = metric_fn(out, target)\n",
    "\n",
    "        wandb.log({\"train/loss\": loss.item(), \"train/metric\": metric}, step=step)\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    return step\n",
    "\n",
    "def train(model, optimizer, train_loader, valid_loader, loss_fn, metric_fn, checkpoint_path, epoch_num=10):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    best_metric = 0\n",
    "    step = 0\n",
    "    for epoch in tqdm(range(epoch_num)):\n",
    "        \n",
    "        step = train_epoch(model, optimizer, train_loader, loss_fn, metric_fn, step)\n",
    "        loss, metric = validation_epoch(model, valid_loader, loss_fn, metric_fn, step)\n",
    "        \n",
    "        if best_metric < metric:\n",
    "            best_metric = metric\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'metric': metric\n",
    "                }, checkpoint_path)\n",
    "        step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6e11a",
   "metadata": {},
   "source": [
    "# Без использования предобученной модели для раскраски изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb6fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id, id_to_class = get_classes_map(ROOT_DIR)\n",
    "\n",
    "\n",
    "train_dataset = FoodDataset(ROOT_DIR, train_class_files, train_class_target, \\\n",
    "                            transform_classic_train, class_to_id, id_to_class)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "\n",
    "valid_dataset = FoodDataset(ROOT_DIR, val_in_files, val_in_target, \\\n",
    "                            transform_classic_valid, class_to_id, id_to_class)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "train_out_dataset = FoodDataset(ROOT_DIR, train_class_files_out, train_class_target_out, \\\n",
    "                                transform_classic_train, class_to_id, id_to_class)\n",
    "train_out_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "\n",
    "valid_out_dataset = FoodDataset(ROOT_DIR, val_out_files, val_out_target, \\\n",
    "                                transform_classic_valid, class_to_id, id_to_class)\n",
    "valid_out_loader = DataLoader(valid_dataset, batch_size=32, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53773a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325093"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetFoodClassifierSmall(nn.Identity(), 3, 101)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=2e-05)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8edcd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"colorization-classifier_small_in\", name=\"classifier_origin_in\")\n",
    "# train(model, optimizer, train_loader, valid_loader, loss_fn, accuracy, checkpoint_path=f\"{CHECKPOINT_DIR}/origin_in.pth\")\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec096ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetFoodClassifierSmall(nn.Identity(), 3, 101)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=2e-05)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612d6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"colorization-classifier_small_out\", name=\"classifier_origin_out\")\n",
    "# train(model, optimizer, train_out_loader, valid_out_loader, loss_fn, accuracy, checkpoint_path=f\"{CHECKPOINT_DIR}/origin_out.pth\")\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033b1dc",
   "metadata": {},
   "source": [
    "# С использованием предобученной модели для раскраски изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d42d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id, id_to_class = get_classes_map(ROOT_DIR)\n",
    "\n",
    "train_dataset = FoodDataset(ROOT_DIR, train_class_files, train_class_target, \\\n",
    "                            transform_colorization_train, class_to_id, id_to_class)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "\n",
    "valid_dataset = FoodDataset(ROOT_DIR, val_in_files, val_in_target, \\\n",
    "                            transform_colorization_valid, class_to_id, id_to_class)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "train_out_dataset = FoodDataset(ROOT_DIR, train_class_files_out, train_class_target_out, \\\n",
    "                                transform_colorization_train, class_to_id, id_to_class)\n",
    "train_out_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "\n",
    "valid_out_dataset = FoodDataset(ROOT_DIR, val_out_files, val_out_target, \\\n",
    "                                transform_colorization_valid, class_to_id, id_to_class)\n",
    "valid_out_loader = DataLoader(valid_dataset, batch_size=32, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d441c656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss']),\n",
       " 14,\n",
       " 0.19743407670991966)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./checkpoint_ae/ae.pth\")\n",
    "checkpoint.keys(), checkpoint[\"epoch\"], checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff5776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE = Autoencoder()\n",
    "AE.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63a1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_backbone = nn.Sequential(AE.encoder, AE.quant_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4e2270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326245"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetFoodClassifierSmall(prefix_backbone, 4, 101)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=2e-05)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2afbddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"colorization-classifier_small_in\", name=\"classifier_color_in\")\n",
    "# train(model, optimizer, train_loader, valid_loader, loss_fn, accuracy, checkpoint_path=f\"{CHECKPOINT_DIR}/color_in.pth\")\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734c07cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetFoodClassifierSmall(prefix_backbone, 4, 101)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=2e-05)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7cdc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"colorization-classifier_small_out\", name=\"classifier_color_out\")\n",
    "# train(model, optimizer, train_out_loader, valid_out_loader, loss_fn, accuracy, checkpoint_path=f\"{CHECKPOINT_DIR}/color_out.pth\")\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af442a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
